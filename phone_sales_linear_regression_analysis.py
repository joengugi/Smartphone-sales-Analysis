# -*- coding: utf-8 -*-
"""Phone sales Linear regression analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1umO5CX9nE8OADjIsUJx5r-xM3pTJpw1M
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from scipy.stats import zscore
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score

# loading the dataset
df = pd.read_csv("Sales.csv")

# Display basic information about the dataset
print(df.info())

# Display summary statistics for numerical variables
print(df.describe())

# Histogram for numerical variables
df.hist(figsize=(10, 8))
plt.tight_layout()
plt.show()

# Set the figure size to make room for longer x-axis labels
plt.figure(figsize=(12, 6))

# Create the scatter plot
sns.scatterplot(x='Brands', y='Selling Price', data = df)

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45)

# Set the y-axis limit to ensure all data points are visible
plt.ylim(0, 250000)

# Add title and labels
plt.title('Scatter Plot of Brands vs Selling Price')
plt.xlabel('Brands')
plt.ylabel('Selling Price')

# Show the plot
plt.show()

# Set the figure size to make room for longer x-axis labels
plt.figure(figsize=(12, 6))

# Create the scatter plot
sns.scatterplot(x='Memory', y='Selling Price', data = df)

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45)

# Set the y-axis limit to ensure all data points are visible
plt.ylim(0, 250000)

# Add title and labels
plt.title('Scatter Plot of Memory vs Selling Price')
plt.xlabel('Memory')
plt.ylabel('Selling Price')

# Show the plot
plt.show()

# Set the figure size to make room for longer x-axis labels
plt.figure(figsize=(12, 6))

# Create the scatter plot
sns.scatterplot(x='Storage', y='Selling Price', data = df)

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45)

# Set the y-axis limit to ensure all data points are visible
plt.ylim(0, 250000)

# Add title and labels
plt.title('Scatter Plot of Storage vs Selling Price')
plt.xlabel('Storage')
plt.ylabel('Selling Price')

# Show the plot
plt.show()

# Count plot for 'Brands'
plt.figure(figsize=(10, 6))
sns.countplot(x='Brands', data=df)
plt.xticks(rotation=45)
plt.title('Distribution of Brands')
plt.show()

# Count plot for 'Brands'
plt.figure(figsize=(10, 6))
sns.countplot(x='Rating', data=df)
plt.xticks(rotation=45)
plt.title('Distribution of Ratings')
plt.show()

# Step 2: Check for missing values
missing_values = df.isnull().sum()
print("Missing Values:")
print(missing_values)

# Handle missing values
# For numerical columns, fill missing values with mean
numerical_cols = df.select_dtypes(include=[np.number]).columns
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())

# For categorical columns, fill missing values with mode
categorical_cols = df.select_dtypes(include=[object]).columns
df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])

# Step 3: Descriptive statistics for numerical columns
print("\n Descriptive Statistics for Numerical Columns:")
print(df.describe())

# Step 4: Explore distributions and relationships
# Pairplot for numerical columns
sns.pairplot(df[numerical_cols])
plt.show()

# Correlation heatmap
correlation_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Step 5: Encode categorical variables
# Use one-hot encoding for categorical variables
df = pd.get_dummies(df, columns=categorical_cols)

# Display updated dataframe
print("\n Updated DataFrame with Encoded Categorical Variables:")
print(df.head())

#Regression Analysis

# Step 1: Split data into features (X) and target variable (y)
X = df.drop(columns=['Selling Price'])
y = df['Selling Price']

# Step 2: Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Step 3: Initialize and train the regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 4: Make predictions on the testing set
y_pred = model.predict(X_test)

# Step 5: Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared:", r2)

# Interpret the coefficients
coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})
print("\n Coefficients:")
print(coefficients)

# Visualize model predictions vs. actual selling prices
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)
plt.xlabel("Actual Selling Prices")
plt.ylabel("Predicted Selling Prices")
plt.title("Model Predictions vs. Actual Selling Prices (Linear Regression)")
plt.show()